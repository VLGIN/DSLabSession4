{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "collect-survival",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile\n",
    "import re\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "import random\n",
    "tf.disable_eager_execution()\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "middle-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN:\n",
    "    def __init__(self,\n",
    "                vocab_size,\n",
    "                embedding_size,\n",
    "                lstm_size,\n",
    "                #pretrained_w2v_path,\n",
    "                batch_size):\n",
    "        self._vocab_size = vocab_size\n",
    "        self._embedding_size = embedding_size\n",
    "        self._lstm_size = lstm_size\n",
    "        self._batch_size = batch_size\n",
    "        \n",
    "        self._data = tf.placeholder(tf.int32, shape=[batch_size, MAX_DOC_LENGTH])\n",
    "        self._labels = tf.placeholder(tf.int32, shape=[batch_size, ])\n",
    "        self._sentence_lengths = tf.placeholder(tf.int32, shape = [batch_size, ])\n",
    "        self._final_token = tf.placeholder(tf.int32, shape = [batch_size, ])\n",
    "    def embedding_layer(self, indices):\n",
    "        pretrained_vectors = []\n",
    "        pretrained_vectors.append(np.zeros(self._embedding_size))\n",
    "        \n",
    "        np.random.seed(2018)\n",
    "        for _ in range(self._vocab_size + 1):\n",
    "            pretrained_vectors.append(np.random.normal(loc = 0., scale = 1., size = self._embedding_size))\n",
    "            \n",
    "        pretrained_vectors = np.array(pretrained_vectors)\n",
    "        \n",
    "        self._embedding_matrix = tf.get_variable(\n",
    "            name='embedding',\n",
    "            shape = (self._vocab_size + 2, self._embedding_size),\n",
    "            initializer = tf.constant_initializer(pretrained_vectors)\n",
    "        )\n",
    "        return tf.nn.embedding_lookup(self._embedding_matrix, indices)\n",
    "    def LSTM_layer(self, embeddings):\n",
    "        lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(self._lstm_size)\n",
    "        zero_state = tf.zeros(shape=(self._batch_size, self._lstm_size))\n",
    "        initial_state = tf.nn.rnn_cell.LSTMStateTuple(zero_state, zero_state)\n",
    "        \n",
    "        lstm_inputs = tf.unstack(\n",
    "            tf.transpose(embeddings, perm=[1,0,2])\n",
    "        )\n",
    "        lstm_outputs, last_state = tf.nn.static_rnn(\n",
    "            cell = lstm_cell,\n",
    "            inputs = lstm_inputs,\n",
    "            initial_state = initial_state,\n",
    "            sequence_length = self._sentence_lengths\n",
    "        )\n",
    "        \n",
    "        lstm_outputs = tf.unstack(\n",
    "            tf.transpose(lstm_outputs, perm = [1,0,2])\n",
    "        )\n",
    "        lstm_outputs = tf.concat(\n",
    "            lstm_outputs,\n",
    "            axis = 0\n",
    "        )\n",
    "        \n",
    "        mask = tf.sequence_mask(\n",
    "            lengths = self._sentence_lengths,\n",
    "            maxlen= MAX_DOC_LENGTH,\n",
    "            dtype = tf.float32\n",
    "        )\n",
    "        mask = tf.concat(tf.unstack(mask, axis = 0), axis = 0)\n",
    "        mask = tf.expand_dims(mask, -1)\n",
    "        lstm_outputs = mask * lstm_outputs\n",
    "        lstm_outputs_split = tf.split(lstm_outputs, num_or_size_splits = self._batch_size)\n",
    "        lstm_outputs_sum = tf.reduce_sum(lstm_outputs_split, axis = 1)\n",
    "        lstm_outputs_average = lstm_outputs_sum / tf.expand_dims(\n",
    "            tf.cast(self._sentence_lengths, tf.float32), \n",
    "            -1\n",
    "        )\n",
    "        return lstm_outputs_average\n",
    "    def build_graph(self):\n",
    "        embeddings = self.embedding_layer(self._data)\n",
    "        lstm_outputs = self.LSTM_layer(embeddings)\n",
    "        \n",
    "        weights = tf.get_variable(\n",
    "            name = 'final_layer_weights',\n",
    "            shape = (self._lstm_size, NUM_CLASSES),\n",
    "            initializer = tf.random_normal_initializer(seed=2018)\n",
    "        )\n",
    "        \n",
    "        biases = tf.get_variable(\n",
    "            name = 'final_layer_biases',\n",
    "            shape = (NUM_CLASSES),\n",
    "            initializer = tf.random_normal_initializer(seed = 2018)\n",
    "        )\n",
    "        \n",
    "        logits = tf.matmul(lstm_outputs, weights) + biases\n",
    "        \n",
    "        labels_one_hot = tf.one_hot(\n",
    "            indices = self._labels,\n",
    "            depth = NUM_CLASSES,\n",
    "            dtype = tf.float32\n",
    "        )\n",
    "        \n",
    "        loss = tf.nn.softmax_cross_entropy_with_logits(\n",
    "            labels = labels_one_hot,\n",
    "            logits = logits\n",
    "        )\n",
    "        \n",
    "        loss = tf.reduce_mean(loss)\n",
    "        probs = tf.nn.softmax(logits)\n",
    "        predicted_labels = tf.argmax(probs, axis = 1)\n",
    "        predicted_labels = tf.squeeze(predicted_labels)\n",
    "        return (predicted_labels, loss)\n",
    "    def trainer(self, loss, learning_rate):\n",
    "        train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "        return train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "noticed-evaluation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader:\n",
    "    def __init__(self, data_path, batch_size):\n",
    "        self._batch_size = batch_size\n",
    "        # Đọc dữ liệu vào\n",
    "        with open(data_path) as f:\n",
    "            d_lines = f.read().splitlines() \n",
    "        \n",
    "        self._data = []\n",
    "        self._labels = []\n",
    "        self._final_tokens = []\n",
    "        self._sentence_length = []\n",
    "        \n",
    "        for data_id, line in enumerate(d_lines):\n",
    "            features = line.split('<fff>')\n",
    "            label, doc_id, sentence_length = int(features[0]), int(features[1]), int(features[2])\n",
    "            tokens = features[3].split()\n",
    "            \n",
    "            \n",
    "            self._data.append(tokens)\n",
    "            self._final_tokens.append(tokens[-1])\n",
    "            self._labels.append(label)\n",
    "            self._sentence_length.append(sentence_length)\n",
    "        \n",
    "        self._data = np.array(self._data)\n",
    "        self._labels = np.array(self._labels)\n",
    "        self._final_tokens = np.array(self._final_tokens)\n",
    "        self._sentence_length = np.array(self._sentence_length)\n",
    "        \n",
    "        self._num_epoch = 0\n",
    "        self._batch_id = 0\n",
    "    def next_batch(self):\n",
    "        start = self._batch_id * self._batch_size\n",
    "        end = start + self._batch_size\n",
    "        self._batch_id += 1\n",
    "        \n",
    "        if start + self._batch_size > len(self._data):\n",
    "            end = len(self._data)\n",
    "            start = len(self._data) - 50\n",
    "            self._num_epoch += 1\n",
    "            self._batch_id = 0\n",
    "            indices = list(range(len(self._data)))\n",
    "            random.seed(2018)\n",
    "            random.shuffle(indices)\n",
    "            self._data, self._labels, self._final_tokens, self._sentence_length = self._data[indices], self._labels[indices], self._final_tokens[indices], self._sentence_length[indices]\n",
    "            \n",
    "        return self._data[start:end], self._labels[start:end], self._sentence_length[start:end], self._final_tokens[start:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opposite-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate_RNN():\n",
    "    with open('dataset/w2v/vocab-raw.txt') as f:\n",
    "        vocab_size = len(f.read().splitlines())\n",
    "        \n",
    "    tf.set_random_seed(2018)\n",
    "    rnn = RNN(\n",
    "        vocab_size=vocab_size,\n",
    "        embedding_size = 300,\n",
    "        lstm_size = 50,\n",
    "        batch_size = 50\n",
    "    )\n",
    "    predicted_labels, loss = rnn.build_graph()\n",
    "    train_op = rnn.trainer(loss = loss,learning_rate = 0.01)\n",
    "    with tf.Session() as sess:\n",
    "        train_data_reader = DataReader(\n",
    "            data_path = 'dataset/w2v/20news-train-encoded.txt',\n",
    "            batch_size = 50\n",
    "        )\n",
    "        \n",
    "        test_data_reader = DataReader(\n",
    "            data_path = 'dataset/w2v/20news-test-encoded.txt',\n",
    "            batch_size = 50\n",
    "        )\n",
    "        step = 0\n",
    "        MAX_STEP = 30000\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        while step < MAX_STEP:\n",
    "            next_train_batch = train_data_reader.next_batch()\n",
    "            train_data, train_labels, train_sentence_lengths, train_final_tokens = next_train_batch\n",
    "            plabels_eval, loss_eval, _ = sess.run(\n",
    "                [predicted_labels, loss, train_op],\n",
    "                feed_dict = {\n",
    "                    rnn._data: train_data,\n",
    "                    rnn._labels: train_labels,\n",
    "                    rnn._sentence_lengths: train_sentence_lengths,\n",
    "                    #rnn._final_tokens: train_final_tokens\n",
    "                }\n",
    "            )\n",
    "            step += 1\n",
    "            if step % 100 == 0:\n",
    "                print ('loss: ', loss_eval)\n",
    "            if train_data_reader._batch_id == 0:\n",
    "                num_true_preds = 0\n",
    "                while True:\n",
    "                    next_test_batch = test_data_reader.next_batch()\n",
    "                    test_data, test_labels, test_sentence_lengths, test_final_tokens = next_test_batch\n",
    "                    \n",
    "                    test_plabels_eval = sess.run(\n",
    "                        predicted_labels,\n",
    "                        feed_dict = {\n",
    "                            rnn._data: test_data,\n",
    "                            rnn._labels: test_labels,\n",
    "                            rnn._sentence_lengths: test_sentence_lengths,\n",
    "                            #rnn._final_tokens: test_final_tokens\n",
    "                        }\n",
    "                    )\n",
    "                    matches = np.equal(test_plabels_eval, test_labels)\n",
    "                    num_true_preds += np.sum(matches.astype(float))\n",
    "                    \n",
    "                    if test_data_reader._batch_id == 0:\n",
    "                        break\n",
    "                print('Epoch: ', train_data_reader._num_epoch)\n",
    "                print('Accuracy on test data: ', num_true_preds * 100 / len(test_data_reader._data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "extreme-testing",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-25b1e1baa1af>:41: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:753: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/keras/layers/legacy_rnn/rnn_cell_impl.py:702: UserWarning: `tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  warnings.warn(\"`tf.nn.rnn_cell.BasicLSTMCell` is deprecated and will be \"\n",
      "/home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer_v1.py:1727: UserWarning: `layer.add_variable` is deprecated and will be removed in a future version. Please use `layer.add_weight` method instead.\n",
      "  warnings.warn('`layer.add_variable` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py:201: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n",
      "loss:  1.3821086\n",
      "loss:  6.10779\n",
      "Epoch:  1\n",
      "Accuracy on test data:  6.571959638874137\n",
      "loss:  1.984223\n",
      "loss:  1.4214394\n",
      "Epoch:  2\n",
      "Accuracy on test data:  71.12320764737122\n",
      "loss:  0.99488336\n",
      "loss:  0.7481438\n",
      "Epoch:  3\n",
      "Accuracy on test data:  76.07541157727032\n",
      "loss:  0.309473\n",
      "loss:  0.3354514\n",
      "loss:  0.24099119\n",
      "Epoch:  4\n",
      "Accuracy on test data:  75.94264471587891\n",
      "loss:  0.03961974\n",
      "loss:  0.04133545\n",
      "Epoch:  5\n",
      "Accuracy on test data:  76.89856611789698\n",
      "loss:  0.01980238\n",
      "loss:  0.014662591\n",
      "Epoch:  6\n",
      "Accuracy on test data:  76.95167286245353\n",
      "loss:  0.006245686\n",
      "loss:  0.0046249824\n",
      "Epoch:  7\n",
      "Accuracy on test data:  77.23048327137546\n",
      "loss:  0.0025788485\n",
      "loss:  0.011362626\n",
      "loss:  0.0032007142\n",
      "Epoch:  8\n",
      "Accuracy on test data:  77.16409984067977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/contextlib.py\", line 135, in __exit__\n",
      "    self.gen.throw(type, value, traceback)\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 5588, in get_controller\n",
      "    yield g\n",
      "  File \"<ipython-input-8-acf1b9fa9d8f>\", line 31, in train_and_evaluate_RNN\n",
      "    plabels_eval, loss_eval, _ = sess.run(\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 967, in run\n",
      "    result = self._run(None, fetches, feed_dict, options_ptr,\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1190, in _run\n",
      "    results = self._do_run(handle, final_targets, final_fetches,\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1368, in _do_run\n",
      "    return self._do_call(_run_fn, feeds, fetches, targets, options,\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1375, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1359, in _run_fn\n",
      "    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1451, in _call_tf_sessionrun\n",
      "    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3437, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-9-5ec3d2ad392c>\", line 2, in <module>\n",
      "    train_and_evaluate_RNN()\n",
      "  File \"<ipython-input-8-acf1b9fa9d8f>\", line 64, in train_and_evaluate_RNN\n",
      "    print('Accuracy on test data: ', num_true_preds * 100 / len(test_data_reader._data))\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/client/session.py\", line 1645, in __exit__\n",
      "    close_thread.join(30.0)\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/threading.py\", line 1037, in join\n",
      "    self._wait_for_tstate_lock(timeout=max(timeout, 0))\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/threading.py\", line 1049, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/inspect.py\", line 1499, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/inspect.py\", line 709, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/leo/anaconda3/envs/internship/lib/python3.9/inspect.py\", line 746, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_controller\u001b[0;34m(self, default)\u001b[0m\n\u001b[1;32m   5587\u001b[0m                  self).get_controller(default) as g, context.graph_mode():\n\u001b[0;32m-> 5588\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5589\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-acf1b9fa9d8f>\u001b[0m in \u001b[0;36mtrain_and_evaluate_RNN\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sentence_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_final_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_train_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             plabels_eval, loss_eval, _ = sess.run(\n\u001b[0m\u001b[1;32m     32\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 967\u001b[0;31m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[1;32m    968\u001b[0m                          run_metadata_ptr)\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1190\u001b[0;31m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0m\u001b[1;32m   1191\u001b[0m                              feed_dict_tensor, options, run_metadata)\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1367\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1368\u001b[0;31m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0m\u001b[1;32m   1369\u001b[0m                            run_metadata)\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1374\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1359\u001b[0;31m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0m\u001b[1;32m   1360\u001b[0m                                       target_list, run_metadata)\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1450\u001b[0m                           run_metadata):\n\u001b[0;32m-> 1451\u001b[0;31m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0m\u001b[1;32m   1452\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-5ec3d2ad392c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNUM_CLASSES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_and_evaluate_RNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-acf1b9fa9d8f>\u001b[0m in \u001b[0;36mtrain_and_evaluate_RNN\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy on test data: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_true_preds\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exec_type, exec_value, exec_tb)\u001b[0m\n\u001b[1;32m   1644\u001b[0m       \u001b[0mclose_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1645\u001b[0;31m       \u001b[0mclose_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m30.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mclose_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0;31m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/internship/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "NUM_CLASSES = 20\n",
    "MAX_DOC_LENGTH = 500\n",
    "\n",
    "train_and_evaluate_RNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-electric",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "internship",
   "language": "python",
   "name": "internship"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
